\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}

\title{
  \vspace{-2cm}
  CS 224n Assignment \#4 \\
  \author{Yoshihiro Kumazawa}
}

\begin{document}
\maketitle
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Neural Machine Translation with RNNs}
  \begin{enumerate}[label=(\alph*)]
    \item See \texttt{utils.py}.
    \item See \texttt{model\_embeddings.py}.
    \item See \texttt{nmt\_model.py}.
    \item See \texttt{nmt\_model.py}.
    \item See \texttt{nmt\_model.py}.
    \item See \texttt{nmt\_model.py}.
    \item The masked logits are made $-\infty$ and hence do not affect the softmax calculation of the other logits. Those masks are put on the hidden states from the padded words, which no attention should be paid to.
    \item (Missing)
    \item The model’s corpus BLEU Score was 35.83.
    \item One advantage of dot product attention compared to multiplicative attention is that it is less prone to overfitting since it does not have weight parameters. One disadvantage is its lower expressivity. One advantage of additive attention compared to multiplicative attention is that it can learn not to be affected by the hidden state very much by letting $W_1$ small. One disadvantage is that it is more prone to overfitting.
  \end{enumerate}
  \item \textbf{Analyzing NMT Systems}
  \begin{enumerate}[label=(\alph*)]
    \item
    \begin{enumerate}[label=\roman*.]
      \item
      \begin{enumerate}[label=\arabic*.]
        \item "Aquí" is translated to "Here's" instead of "So". "favorite" is redundant.
        \item "Aquí" could be "Here", but the verb "is" is unnecessary anyway. A possible reason is that sentences with no verb were seldom fed during training time. The reason the NMT translated "otro" into "another favorite" instead of "another one" might be that NMT thought it could improve translation accuracy by understanding what such demonstrative words actually mean.
        \item For the first error, feeding more data without verbs might work. For the second error, penalizing redundancy might be a good idea.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item The latter half of the translation does not make sense.
        \item Probably the model tried to directly translate the Spanish sentence word-by-word, which ended up producing the wrong sentence. Chances are the source sentence was inherently hard to translate due to some linguistic difference between Spanish and English.
        \item To encourage the network to avoid unnatural direct translations, feeding more data where the reference translations are very different from possible direct translations might work.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item "Bolingbroke" is interpreted as unknown.
        \item This is simply because the model did not encounter the word "Bolingbroke" during training time.
        \item One can either add such proper nouns to the vocabulary or let the network treat unseen words as they are (i.e. do not translate them). To implement the latter idea, imagine you have unknown words in the source sentence and you have got \textless\textit{unk}\textgreater tokens during translation. You can use the attention vector to guess which word in the source language each of those unknown words corresponds to.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item The idiom "dar vuelta a la manzana" is translated to "go back to the apple" unlike "go around the block" in the reference translation.
        \item The model directly translated the idiom to "go back to the apple", which is less meaningful in English.
        \item One possible way to get around this is pre-translate such idioms in the training set and do not let the machine learn the direct translation. More precisely, during translation we can replace the idiom by some random word which is not in the vocabulary, run the NMT and replace the possible unknown token in the target sentence which we expect has a high attention score on the random word representing the idiom.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item "la sala de profesores" is translated to "the women's" room" unlike "the teacher's lounge" in the reference translation.
        \item It might be because the model encountered so many examples of women's bathrooms that it translated the sentence in that way. Another reason might be that the subject of the sentence is "she", which encouraged the machine to predict the inappropriate "women's room".
        \item Feeding more data might possibly solve the problem.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item "100,000 hect´areas" is translated to "100,000 acres" unlike "250 thousand acres" in the reference translation.
        \item This is a unit conversion error.
        \item One possible way is to pre-convert such quantities with units which are rarely used in English. My solution for (iv) with an easy calculation might work for that.
      \end{enumerate}
    \end{enumerate}
    \item
    \item
    \begin{enumerate}[label=\roman*.]
      \item
      \item
      \item
      \item
    \end{enumerate}
  \end{enumerate}
\end{enumerate}
\end{document}
