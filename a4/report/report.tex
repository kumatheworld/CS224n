\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}

\title{
  \vspace{-2cm}
  CS 224n Assignment \#4 \\
  \author{Yoshihiro Kumazawa}
}

\begin{document}
\maketitle
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Neural Machine Translation with RNNs}
  \begin{enumerate}[label=(\alph*)]
    \item See \texttt{utils.py}.
    \item See \texttt{model\_embeddings.py}.
    \item See \texttt{nmt\_model.py}.
    \item See \texttt{nmt\_model.py}.
    \item See \texttt{nmt\_model.py}.
    \item See \texttt{nmt\_model.py}.
    \item The masked logits are made $-\infty$ and hence do not affect the softmax calculation of the other logits. Those masks are put on the hidden states from the padded words, which no attention should be paid to.
    \item (Missing)
    \item The model’s corpus BLEU Score was 35.83.
    \item One advantage of dot product attention compared to multiplicative attention is that it is less prone to overfitting since it does not have weight parameters. One disadvantage is its lower expressivity. One advantage of additive attention compared to multiplicative attention is that it can learn not to be affected by the hidden state very much by letting $W_1$ small. One disadvantage is that it is more prone to overfitting.
  \end{enumerate}
  \item \textbf{Analyzing NMT Systems}
  \begin{enumerate}[label=(\alph*)]
    \item
    \begin{enumerate}[label=\roman*.]
      \item
      \begin{enumerate}[label=\arabic*.]
        \item "Aquí" is translated to "Here's" instead of "So". "favorite" is redundant.
        \item "Aquí" could be "Here", but the verb "is" is unnecessary anyway. A possible reason is that sentences with no verb were seldom fed during training time. The reason the NMT translated "otro" into "another favorite" instead of "another one" might be that NMT thought it could improve translation accuracy by understanding what such demonstrative words actually mean.
        \item For the first error, feeding more data without verbs might work. For the second error, penalizing redundancy might be a good idea.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item The latter half of the translation does not make sense.
        \item Probably the model tried to directly translate the Spanish sentence word-by-word, which ended up producing the wrong sentence. Chances are the source sentence was inherently hard to translate due to some linguistic difference between Spanish and English.
        \item To encourage the network to avoid unnatural direct translations, feeding more data where the reference translations are very different from possible direct translations might work.
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item
        \item
        \item
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item
        \item
        \item
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item
        \item
        \item
      \end{enumerate}
      \item
      \begin{enumerate}[label=\arabic*.]
        \item
        \item
        \item
      \end{enumerate}
    \end{enumerate}
    \item
    \item
    \begin{enumerate}[label=\roman*.]
      \item
      \item
      \item
      \item
    \end{enumerate}
  \end{enumerate}
\end{enumerate}
\end{document}
